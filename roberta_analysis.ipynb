{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa Sentiment Analysis\n",
    "\n",
    "This notebook adds RoBERTa sentiment analysis to the existing VADER and FinBERT results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewlee/myenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18778 posts\n"
     ]
    }
   ],
   "source": [
    "# Load data that already has VADER and FinBERT sentiment scores\n",
    "df_truth = pd.read_csv('data/truth_social_with_sentiment.csv')\n",
    "df_truth['date'] = pd.to_datetime(df_truth['date'])\n",
    "\n",
    "print(f\"{len(df_truth)} posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating RoBERTa sentiment scores\n",
      "Processed 1000 posts...\n",
      "Processed 2000 posts...\n",
      "Processed 3000 posts...\n",
      "Processed 4000 posts...\n",
      "Processed 5000 posts...\n",
      "Processed 6000 posts...\n",
      "Processed 7000 posts...\n",
      "Processed 8000 posts...\n",
      "Processed 9000 posts...\n",
      "Processed 10000 posts...\n",
      "Processed 11000 posts...\n",
      "Processed 12000 posts...\n",
      "Processed 13000 posts...\n",
      "Processed 14000 posts...\n",
      "Processed 15000 posts...\n",
      "Processed 16000 posts...\n",
      "Processed 17000 posts...\n",
      "Processed 18000 posts...\n",
      "Sentiment score range: -0.959 to 0.989\n",
      "Average sentiment: 0.020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>finbert_sentiment</th>\n",
       "      <th>roberta_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am on my way to Malaysia, where I will sign ...</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.080414</td>\n",
       "      <td>-0.053873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @realDonaldTrumpCanada was caught, red hand...</td>\n",
       "      <td>-0.8329</td>\n",
       "      <td>-0.353714</td>\n",
       "      <td>-0.709411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canada was caught, red handed, putting up a fr...</td>\n",
       "      <td>-0.8329</td>\n",
       "      <td>-0.300146</td>\n",
       "      <td>-0.710382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have a very strong PEACE in the Middle East...</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.027445</td>\n",
       "      <td>0.668038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Congressman Jimmy Patronis is a MAGA Warrior w...</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.154830</td>\n",
       "      <td>0.968299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Richard Hudson is a Great Man, and TREMENDOUS ...</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.394976</td>\n",
       "      <td>0.965736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Congressman David Rouzer is a terrific Represe...</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.239225</td>\n",
       "      <td>0.958171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Congressman Addison McDowell is an America Fir...</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.200672</td>\n",
       "      <td>0.967453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Congresswoman Nicole Malliotakis is a Tremendo...</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.254401</td>\n",
       "      <td>0.965822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Congressman Jack Bergman is a Tremendous Champ...</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.238671</td>\n",
       "      <td>0.969030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     cleaned_content  vader_sentiment  \\\n",
       "0  I am on my way to Malaysia, where I will sign ...           0.9682   \n",
       "1  RT @realDonaldTrumpCanada was caught, red hand...          -0.8329   \n",
       "2  Canada was caught, red handed, putting up a fr...          -0.8329   \n",
       "3  We have a very strong PEACE in the Middle East...           0.9074   \n",
       "4  Congressman Jimmy Patronis is a MAGA Warrior w...           0.9643   \n",
       "5  Richard Hudson is a Great Man, and TREMENDOUS ...           0.9905   \n",
       "6  Congressman David Rouzer is a terrific Represe...           0.9800   \n",
       "7  Congressman Addison McDowell is an America Fir...           0.9907   \n",
       "8  Congresswoman Nicole Malliotakis is a Tremendo...           0.9922   \n",
       "9  Congressman Jack Bergman is a Tremendous Champ...           0.9826   \n",
       "\n",
       "   finbert_sentiment  roberta_sentiment  \n",
       "0           0.080414          -0.053873  \n",
       "1          -0.353714          -0.709411  \n",
       "2          -0.300146          -0.710382  \n",
       "3           0.027445           0.668038  \n",
       "4           0.154830           0.968299  \n",
       "5           0.394976           0.965736  \n",
       "6           0.239225           0.958171  \n",
       "7           0.200672           0.967453  \n",
       "8           0.254401           0.965822  \n",
       "9           0.238671           0.969030  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to get RoBERTa sentiment for one text\n",
    "def get_roberta_sentiment(text):\n",
    "    # Skip empty texts\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return 0.0\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # RoBERTa labels: negative=0, neutral=1, positive=2\n",
    "    negative_prob = predictions[0][0].item()\n",
    "    neutral_prob = predictions[0][1].item()\n",
    "    positive_prob = predictions[0][2].item()\n",
    "    \n",
    "    # Return score: positive - negative (range: -1 to +1)\n",
    "    score = positive_prob - negative_prob\n",
    "    return score\n",
    "\n",
    "# Apply RoBERTa to all posts\n",
    "print(\"Calculating RoBERTa sentiment scores\")\n",
    "roberta_scores = []\n",
    "total_posts = len(df_truth)\n",
    "\n",
    "for i in range(total_posts):\n",
    "    text = df_truth['cleaned_content'].iloc[i]\n",
    "    score = get_roberta_sentiment(text)\n",
    "    roberta_scores.append(score)\n",
    "    \n",
    "    # every 1000 posts\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Processed {i + 1} posts...\")\n",
    "\n",
    "df_truth['roberta_sentiment'] = roberta_scores\n",
    "\n",
    "print(f\"Sentiment score range: {df_truth['roberta_sentiment'].min():.3f} to {df_truth['roberta_sentiment'].max():.3f}\")\n",
    "print(f\"Average sentiment: {df_truth['roberta_sentiment'].mean():.3f}\")\n",
    "df_truth[['cleaned_content', 'vader_sentiment', 'finbert_sentiment', 'roberta_sentiment']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily RoBERTa sentiment calculated for 1269 days\n",
      "Average daily RoBERTa sentiment range: -0.878 to 0.981\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>post_count</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>avg_finbert_sentiment</th>\n",
       "      <th>avg_roberta_sentiment</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.297050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.072096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.070266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.083299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.502188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-01-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.501625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  post_count  avg_sentiment  avg_finbert_sentiment  \\\n",
       "0 2022-01-03         0.0            0.0                    0.0   \n",
       "1 2022-01-04         0.0            0.0                    0.0   \n",
       "2 2022-01-05         0.0            0.0                    0.0   \n",
       "3 2022-01-06         0.0            0.0                    0.0   \n",
       "4 2022-01-07         0.0            0.0                    0.0   \n",
       "5 2022-01-10         0.0            0.0                    0.0   \n",
       "6 2022-01-11         0.0            0.0                    0.0   \n",
       "7 2022-01-12         0.0            0.0                    0.0   \n",
       "8 2022-01-13         0.0            0.0                    0.0   \n",
       "9 2022-01-14         0.0            0.0                    0.0   \n",
       "\n",
       "   avg_roberta_sentiment   Returns  \n",
       "0                    0.0       NaN  \n",
       "1                    0.0 -1.297050  \n",
       "2                    0.0 -3.072096  \n",
       "3                    0.0 -0.070266  \n",
       "4                    0.0 -1.083299  \n",
       "5                    0.0  0.065836  \n",
       "6                    0.0  1.502188  \n",
       "7                    0.0  0.396576  \n",
       "8                    0.0 -2.501625  \n",
       "9                    0.0  0.622266  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load combined market data\n",
    "combined_df = pd.read_csv('data/combined_data_with_sentiment.csv')\n",
    "\n",
    "# Ensure dates are datetime\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "df_truth['date'] = pd.to_datetime(df_truth['date'])\n",
    "\n",
    "# Calculate average\n",
    "daily_roberta = df_truth.groupby('date')['roberta_sentiment'].mean().reset_index(name='avg_roberta_sentiment')\n",
    "\n",
    "combined_df = pd.merge(combined_df, daily_roberta, on='date', how='left')\n",
    "combined_df['avg_roberta_sentiment'] = combined_df['avg_roberta_sentiment'].fillna(0)\n",
    "\n",
    "print(f\"Daily RoBERTa sentiment calculated for {len(daily_roberta)} days\")\n",
    "print(f\"Average daily RoBERTa sentiment range: {daily_roberta['avg_roberta_sentiment'].min():.3f} to {daily_roberta['avg_roberta_sentiment'].max():.3f}\")\n",
    "combined_df[['date', 'post_count', 'avg_sentiment', 'avg_finbert_sentiment', 'avg_roberta_sentiment', 'Returns']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with QQQ Returns:\n",
      "VADER: 0.0329\n",
      "FinBERT: -0.0162\n",
      "RoBERTa: -0.0097\n",
      "\n",
      "Correlation between models: **Higher = models agree more**\n",
      "VADER vs FinBERT: 0.6467\n",
      "VADER vs RoBERTa: 0.7563\n",
      "FinBERT vs RoBERTa: 0.8149\n"
     ]
    }
   ],
   "source": [
    "# Compare correlations with QQQ returns\n",
    "vader_corr = combined_df['avg_sentiment'].corr(combined_df['Returns'])\n",
    "finbert_corr = combined_df['avg_finbert_sentiment'].corr(combined_df['Returns'])\n",
    "roberta_corr = combined_df['avg_roberta_sentiment'].corr(combined_df['Returns'])\n",
    "\n",
    "print(\"Correlation with QQQ Returns:\")\n",
    "print(f\"VADER: {round(vader_corr, 4)}\")\n",
    "print(f\"FinBERT: {round(finbert_corr, 4)}\")\n",
    "print(f\"RoBERTa: {round(roberta_corr, 4)}\")\n",
    "\n",
    "# Compare how much the models agree with each other\n",
    "vader_finbert = combined_df['avg_sentiment'].corr(combined_df['avg_finbert_sentiment'])\n",
    "vader_roberta = combined_df['avg_sentiment'].corr(combined_df['avg_roberta_sentiment'])\n",
    "finbert_roberta = combined_df['avg_finbert_sentiment'].corr(combined_df['avg_roberta_sentiment'])\n",
    "\n",
    "print(\"\\nCorrelation between models: **Higher = models agree more**\")\n",
    "print(f\"VADER vs FinBERT: {round(vader_finbert, 4)}\")\n",
    "print(f\"VADER vs RoBERTa: {round(vader_roberta, 4)}\")\n",
    "print(f\"FinBERT vs RoBERTa: {round(finbert_roberta, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new results\n",
    "df_truth.to_csv('data/truth_social_after_roberta.csv', index=False)\n",
    "combined_df.to_csv('data/combined_data_after_roberta.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
